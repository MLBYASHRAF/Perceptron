{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b02932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8417bd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6676884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b6218",
   "metadata": {},
   "source": [
    "1e-4=10^-4,\n",
    "eta=learning rate,\n",
    "underscore is hidden method thatswhy we're using(not some protective method though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,eta:float=None,epochs:int=None):\n",
    "        self.weights=np.random.randn(3)*1e-4\n",
    "        self.eta=eta #learning rate\n",
    "        self.epochs=epoch #iteration\n",
    "    def _z_outcome(self,input,weights):\n",
    "        return np.dot(input,wights)\n",
    "    def activation_function(self,z):\n",
    "        return np.where(z>0,1,0)\n",
    "    def fit(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        \n",
    "        X_with_bias=np.c_[self.X,-np.ones(len(self.X),1)]\n",
    "        print(f\"X with bias:\\n{X_with_bias}\")\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            z=self._z_outcome(X_with_bias,self.weights)\n",
    "            y_hat=self.activation_function(z)\n",
    "            \n",
    "            self.error=self.y-y_hat\n",
    "            \n",
    "            self.weights=self.weights+self.eta * np.dot(X_with_bias.T,self.error)\n",
    "      \n",
    "    def predict(self,X):\n",
    "        X_with_bias=np.c_[X,-np.ones(len(self.X),1)]\n",
    "        z=self._z_outcome(X_with_bias,self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eac23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
